{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from: https://github.com/Curt-Park/rainbow-is-all-you-need/blob/master/08.rainbow.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "import random\n",
    "from collections import deque\n",
    "# from typing import Deque, Dict, List, Tuple\n",
    "\n",
    "import gym\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from IPython.display import clear_output\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "\n",
    "\n",
    "from segment_tree import MinSegmentTree, SumSegmentTree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replay Buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayBuffer:\n",
    "    \"\"\"A simple numpy replay buffer.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, \n",
    "        obs_dim, \n",
    "        size: int, \n",
    "        batch_size: int = 64, \n",
    "        n_step: int = 1, \n",
    "        gamma: float = 0.97\n",
    "    ):\n",
    "#         print(obs_dim)\n",
    "        self.obs_buf = np.zeros([size, *obs_dim], dtype=np.float32)\n",
    "        self.next_obs_buf = np.zeros([size, *obs_dim], dtype=np.float32)\n",
    "        self.acts_buf = np.zeros([size], dtype=np.float32)\n",
    "        self.rews_buf = np.zeros([size], dtype=np.float32)\n",
    "        self.done_buf = np.zeros(size, dtype=np.float32)\n",
    "        self.max_size, self.batch_size = size, batch_size\n",
    "        self.ptr, self.size, = 0, 0\n",
    "        \n",
    "        # for N-step Learning\n",
    "        self.n_step_buffer = deque(maxlen=n_step)\n",
    "        self.n_step = n_step\n",
    "        self.gamma = gamma\n",
    "\n",
    "    def store(\n",
    "        self, \n",
    "        obs: np.ndarray, \n",
    "        act: np.ndarray, \n",
    "        rew: float, \n",
    "        next_obs: np.ndarray, \n",
    "        done: bool):\n",
    "        transition = (obs, act, rew, next_obs, done)\n",
    "        self.n_step_buffer.append(transition)\n",
    "\n",
    "        # single step transition is not ready\n",
    "        if len(self.n_step_buffer) < self.n_step:\n",
    "            return ()\n",
    "        \n",
    "        # make a n-step transition\n",
    "        rew, next_obs, done = self._get_n_step_info(\n",
    "            self.n_step_buffer, self.gamma\n",
    "        )\n",
    "        obs, act = self.n_step_buffer[0][:2]\n",
    "        \n",
    "        self.obs_buf[self.ptr] = obs\n",
    "        self.next_obs_buf[self.ptr] = next_obs\n",
    "        self.acts_buf[self.ptr] = act\n",
    "        self.rews_buf[self.ptr] = rew\n",
    "        self.done_buf[self.ptr] = done\n",
    "        self.ptr = (self.ptr + 1) % self.max_size\n",
    "        self.size = min(self.size + 1, self.max_size)\n",
    "        \n",
    "        return self.n_step_buffer[0]\n",
    "\n",
    "    def sample_batch(self):\n",
    "        idxs = np.random.choice(self.size, size=self.batch_size, replace=False)\n",
    "\n",
    "        return dict(\n",
    "            obs=self.obs_buf[idxs],\n",
    "            next_obs=self.next_obs_buf[idxs],\n",
    "            acts=self.acts_buf[idxs],\n",
    "            rews=self.rews_buf[idxs],\n",
    "            done=self.done_buf[idxs],\n",
    "            # for N-step Learning\n",
    "            indices=indices,\n",
    "        )\n",
    "    \n",
    "    def sample_batch_from_idxs(self, idxs: np.ndarray):\n",
    "        # for N-step Learning\n",
    "        return dict(\n",
    "            obs=self.obs_buf[idxs],\n",
    "            next_obs=self.next_obs_buf[idxs],\n",
    "            acts=self.acts_buf[idxs],\n",
    "            rews=self.rews_buf[idxs],\n",
    "            done=self.done_buf[idxs],\n",
    "        )\n",
    "    \n",
    "    def _get_n_step_info(self, n_step_buffer, gamma: float):\n",
    "        \"\"\"Return n step rew, next_obs, and done.\"\"\"\n",
    "        # info of the last transition\n",
    "        rew, next_obs, done = n_step_buffer[-1][-3:]\n",
    "\n",
    "        for transition in reversed(list(n_step_buffer)[:-1]):\n",
    "            r, n_o, d = transition[-3:]\n",
    "\n",
    "            rew = r + gamma * rew * (1 - d)\n",
    "            next_obs, done = (n_o, d) if d else (next_obs, done)\n",
    "\n",
    "        return rew, next_obs, done\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return self.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prioritized Replay Buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrioritizedReplayBuffer(ReplayBuffer):\n",
    "    \"\"\"Prioritized Replay buffer.\n",
    "    \n",
    "    Attributes:\n",
    "        max_priority (float): max priority\n",
    "        tree_ptr (int): next index of tree\n",
    "        alpha (float): alpha parameter for prioritized replay buffer\n",
    "        sum_tree (SumSegmentTree): sum tree for prior\n",
    "        min_tree (MinSegmentTree): min tree for min prior to get max weight\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self, \n",
    "        obs_dim, \n",
    "        size: int, \n",
    "        batch_size: int = 64, \n",
    "        alpha: float = 0.6,\n",
    "        n_step: int = 1, \n",
    "        gamma: float = 0.97,\n",
    "    ):\n",
    "        \"\"\"Initialization.\"\"\"\n",
    "        assert alpha >= 0\n",
    "        \n",
    "        super(PrioritizedReplayBuffer, self).__init__(\n",
    "            obs_dim, size, batch_size, n_step, gamma\n",
    "        )\n",
    "        self.max_priority, self.tree_ptr = 1.0, 0\n",
    "        self.alpha = alpha\n",
    "        \n",
    "        # capacity must be positive and a power of 2.\n",
    "        tree_capacity = 1\n",
    "        while tree_capacity < self.max_size:\n",
    "            tree_capacity *= 2\n",
    "\n",
    "        self.sum_tree = SumSegmentTree(tree_capacity)\n",
    "        self.min_tree = MinSegmentTree(tree_capacity)\n",
    "        \n",
    "    def store(\n",
    "        self, \n",
    "        obs: np.ndarray, \n",
    "        act: int, \n",
    "        rew: float, \n",
    "        next_obs: np.ndarray, \n",
    "        done: bool):\n",
    "        \"\"\"Store experience and priority.\"\"\"\n",
    "        transition = super().store(obs, act, rew, next_obs, done)\n",
    "        \n",
    "        if transition:\n",
    "            self.sum_tree[self.tree_ptr] = self.max_priority ** self.alpha\n",
    "            self.min_tree[self.tree_ptr] = self.max_priority ** self.alpha\n",
    "            self.tree_ptr = (self.tree_ptr + 1) % self.max_size\n",
    "        \n",
    "        return transition\n",
    "\n",
    "    def sample_batch(self, beta: float = 0.4):\n",
    "        \"\"\"Sample a batch of experiences.\"\"\"\n",
    "        assert len(self) >= self.batch_size\n",
    "        assert beta > 0\n",
    "        \n",
    "        indices = self._sample_proportional()\n",
    "        \n",
    "        obs = self.obs_buf[indices]\n",
    "        next_obs = self.next_obs_buf[indices]\n",
    "        acts = self.acts_buf[indices]\n",
    "        rews = self.rews_buf[indices]\n",
    "        done = self.done_buf[indices]\n",
    "        weights = np.array([self._calculate_weight(i, beta) for i in indices])\n",
    "        \n",
    "        return dict(\n",
    "            obs=obs,\n",
    "            next_obs=next_obs,\n",
    "            acts=acts,\n",
    "            rews=rews,\n",
    "            done=done,\n",
    "            weights=weights,\n",
    "            indices=indices,\n",
    "        )\n",
    "        \n",
    "    def update_priorities(self, indices, priorities: np.ndarray):\n",
    "        \"\"\"Update priorities of sampled transitions.\"\"\"\n",
    "        assert len(indices) == len(priorities)\n",
    "\n",
    "        for idx, priority in zip(indices, priorities):\n",
    "            assert priority > 0\n",
    "            assert 0 <= idx < len(self)\n",
    "\n",
    "            self.sum_tree[idx] = priority ** self.alpha\n",
    "            self.min_tree[idx] = priority ** self.alpha\n",
    "\n",
    "            self.max_priority = max(self.max_priority, priority)\n",
    "            \n",
    "    def _sample_proportional(self):\n",
    "        \"\"\"Sample indices based on proportions.\"\"\"\n",
    "        indices = []\n",
    "        p_total = self.sum_tree.sum(0, len(self) - 1)\n",
    "        segment = p_total / self.batch_size\n",
    "        \n",
    "        for i in range(self.batch_size):\n",
    "            a = segment * i\n",
    "            b = segment * (i + 1)\n",
    "            upperbound = random.uniform(a, b)\n",
    "            idx = self.sum_tree.retrieve(upperbound)\n",
    "            indices.append(idx)\n",
    "            \n",
    "        return indices\n",
    "    \n",
    "    def _calculate_weight(self, idx: int, beta: float):\n",
    "        \"\"\"Calculate the weight of the experience at idx.\"\"\"\n",
    "        # get max weight\n",
    "        p_min = self.min_tree.min() / self.sum_tree.sum()\n",
    "        max_weight = (p_min * len(self)) ** (-beta)\n",
    "        \n",
    "        # calculate weights\n",
    "        p_sample = self.sum_tree[idx] / self.sum_tree.sum()\n",
    "        weight = (p_sample * len(self)) ** (-beta)\n",
    "        weight = weight / max_weight\n",
    "        \n",
    "        return weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Noisy Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NoisyLinear(nn.Module):\n",
    "    \"\"\"Noisy linear module for NoisyNet.\n",
    "    \n",
    "    \n",
    "        \n",
    "    Attributes:\n",
    "        in_features (int): input size of linear module\n",
    "        out_features (int): output size of linear module\n",
    "        std_init (float): initial std value\n",
    "        weight_mu (nn.Parameter): mean value weight parameter\n",
    "        weight_sigma (nn.Parameter): std value weight parameter\n",
    "        bias_mu (nn.Parameter): mean value bias parameter\n",
    "        bias_sigma (nn.Parameter): std value bias parameter\n",
    "        \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, \n",
    "        in_features: int, \n",
    "        out_features: int, \n",
    "        std_init: float = 0.1,\n",
    "    ):\n",
    "        \"\"\"Initialization.\"\"\"\n",
    "        super(NoisyLinear, self).__init__()\n",
    "        \n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.std_init = std_init\n",
    "\n",
    "        self.weight_mu = nn.Parameter(torch.Tensor(out_features, in_features))\n",
    "        self.weight_sigma = nn.Parameter(\n",
    "            torch.Tensor(out_features, in_features)\n",
    "        )\n",
    "        self.register_buffer(\n",
    "            \"weight_epsilon\", torch.Tensor(out_features, in_features)\n",
    "        )\n",
    "\n",
    "        self.bias_mu = nn.Parameter(torch.Tensor(out_features))\n",
    "        self.bias_sigma = nn.Parameter(torch.Tensor(out_features))\n",
    "        self.register_buffer(\"bias_epsilon\", torch.Tensor(out_features))\n",
    "\n",
    "        self.reset_parameters()\n",
    "        self.reset_noise()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        \"\"\"Reset trainable network parameters (factorized gaussian noise).\"\"\"\n",
    "        mu_range = 1 / math.sqrt(self.in_features)\n",
    "        self.weight_mu.data.uniform_(-mu_range, mu_range)\n",
    "        self.weight_sigma.data.fill_(\n",
    "            self.std_init / math.sqrt(self.in_features)\n",
    "        )\n",
    "        self.bias_mu.data.uniform_(-mu_range, mu_range)\n",
    "        self.bias_sigma.data.fill_(\n",
    "            self.std_init / math.sqrt(self.out_features)\n",
    "        )\n",
    "\n",
    "    def reset_noise(self):\n",
    "        \"\"\"Make new noise.\"\"\"\n",
    "        epsilon_in = self.scale_noise(self.in_features)\n",
    "        epsilon_out = self.scale_noise(self.out_features)\n",
    "\n",
    "        # outer product\n",
    "        self.weight_epsilon.copy_(epsilon_out.ger(epsilon_in))\n",
    "        self.bias_epsilon.copy_(epsilon_out)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Forward method implementation.\n",
    "        \n",
    "        We don't use separate statements on train / eval mode.\n",
    "        It doesn't show remarkable difference of performance.\n",
    "        \"\"\"\n",
    "        return F.linear(\n",
    "            x,\n",
    "            self.weight_mu + self.weight_sigma * self.weight_epsilon,\n",
    "            self.bias_mu + self.bias_sigma * self.bias_epsilon,\n",
    "        )\n",
    "    \n",
    "    @staticmethod\n",
    "    def scale_noise(size: int) -> torch.Tensor:\n",
    "        \"\"\"Set scale to make noise (factorized gaussian noise).\"\"\"\n",
    "        x = torch.FloatTensor(np.random.normal(loc=0.0, scale=1.0, size=size))\n",
    "\n",
    "        return x.sign().mul(x.abs().sqrt())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "\n",
    "USE_CUDA = torch.cuda.is_available()\n",
    "\n",
    "def safelife_cnn(input_shape):\n",
    "    \"\"\"\n",
    "    Defines a CNN with good default values for safelife.\n",
    "\n",
    "    This works best for inputs of size 25x25.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    input_shape : tuple of ints\n",
    "        Height, width, and number of channels for the board.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    cnn : torch.nn.Sequential\n",
    "    output_shape : tuple of ints\n",
    "        Channels, width, and height.\n",
    "\n",
    "    Returns both the CNN module and the final output shape.\n",
    "    \"\"\"\n",
    "    h, w, c = input_shape\n",
    "    cnn = nn.Sequential(\n",
    "        nn.Conv2d(c, 32, kernel_size=5, stride=2),\n",
    "        nn.ReLU(),\n",
    "        nn.Conv2d(32, 64, kernel_size=3, stride=2),\n",
    "        nn.ReLU(),\n",
    "        nn.Conv2d(64, 64, kernel_size=3, stride=1),\n",
    "        nn.ReLU()\n",
    "    )\n",
    "    h = (h-4+1)//2\n",
    "    h = (h-2+1)//2\n",
    "    h = (h-2)\n",
    "    w = (w-4+1)//2\n",
    "    w = (w-2+1)//2\n",
    "    w = (w-2)\n",
    "    return cnn, (64, w, h)\n",
    "\n",
    "\n",
    "class SafeLifeQNetwork(nn.Module):\n",
    "    \"\"\"\n",
    "    Module for calculating Q functions.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_shape):\n",
    "        super().__init__()\n",
    "\n",
    "        self.cnn, cnn_out_shape = safelife_cnn(input_shape)\n",
    "        num_features = np.product(cnn_out_shape)\n",
    "        num_actions = 9\n",
    "\n",
    "        self.advantages = nn.Sequential(\n",
    "            nn.Linear(num_features, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, num_actions)\n",
    "        )\n",
    "\n",
    "        self.value_func = nn.Sequential(\n",
    "            nn.Linear(num_features, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, obs):\n",
    "        # Switch observation to (c, w, h) instead of (h, w, c)\n",
    "        obs = obs.transpose(-1, -3)\n",
    "        x = self.cnn(obs).flatten(start_dim=1)\n",
    "        advantages = self.advantages(x)\n",
    "        value = self.value_func(x)\n",
    "        qval = value + advantages - advantages.mean()\n",
    "        return qval\n",
    "\n",
    "\n",
    "class RainbowNetwork(nn.Module):\n",
    "    def __init__(\n",
    "        self, \n",
    "        in_dim, \n",
    "        out_dim: int, #Number Actions \n",
    "        atom_size: int, \n",
    "        support: torch.Tensor\n",
    "    ):\n",
    "        \"\"\"Initialization.\"\"\"\n",
    "        super(RainbowNetwork, self).__init__()\n",
    "        \n",
    "        self.support = support\n",
    "        self.out_dim = out_dim\n",
    "        self.atom_size = atom_size\n",
    "\n",
    "        # set common feature layer\n",
    "        self.cnn, cnn_out_shape = safelife_cnn(in_dim)\n",
    "        num_features = np.product(cnn_out_shape)\n",
    "\n",
    "        \n",
    "#         self.feature_layer = nn.Sequential(\n",
    "#             nn.Linear(in_dim, 128), \n",
    "#             nn.ReLU(),\n",
    "#         )\n",
    "        \n",
    "        # set advantage layer\n",
    "        self.advantage_hidden_layer = NoisyLinear(num_features, 128)\n",
    "        self.advantage_layer = NoisyLinear(128, out_dim * atom_size)\n",
    "\n",
    "        # set value layer\n",
    "        self.value_hidden_layer = NoisyLinear(num_features, 128)\n",
    "        self.value_layer = NoisyLinear(128, atom_size)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Forward method implementation.\"\"\"\n",
    "        dist = self.dist(x)\n",
    "        q = torch.sum(dist * self.support, dim=2)\n",
    "        \n",
    "        return q\n",
    "    \n",
    "    def dist(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Get distribution for atoms.\"\"\"\n",
    "        x = x.transpose(-1, -3)\n",
    "        feature = self.cnn(x).flatten(start_dim=1) #self.feature_layer(x)\n",
    "        adv_hid = F.relu(self.advantage_hidden_layer(feature))\n",
    "        val_hid = F.relu(self.value_hidden_layer(feature))\n",
    "        \n",
    "        advantage = self.advantage_layer(adv_hid).view(\n",
    "            -1, self.out_dim, self.atom_size\n",
    "        )\n",
    "        value = self.value_layer(val_hid).view(-1, 1, self.atom_size)\n",
    "        q_atoms = value + advantage - advantage.mean(dim=1, keepdim=True)\n",
    "        \n",
    "        dist = F.softmax(q_atoms, dim=-1)\n",
    "        dist = dist.clamp(min=1e-3)  # for avoiding nans\n",
    "        \n",
    "        return dist\n",
    "    \n",
    "    def reset_noise(self):\n",
    "        \"\"\"Reset all noisy layers.\"\"\"\n",
    "        self.advantage_hidden_layer.reset_noise()\n",
    "        self.advantage_layer.reset_noise()\n",
    "        self.value_hidden_layer.reset_noise()\n",
    "        self.value_layer.reset_noise()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQNAgent:\n",
    "    \"\"\"DQN Agent interacting with environment.\n",
    "    \n",
    "    Attribute:\n",
    "        env (gym.Env): openAI Gym environment\n",
    "        memory (PrioritizedReplayBuffer): replay memory to store transitions\n",
    "        batch_size (int): batch size for sampling\n",
    "        target_update (int): period for target model's hard update\n",
    "        gamma (float): discount factor\n",
    "        dqn (Network): model to train and select actions\n",
    "        dqn_target (Network): target model to update\n",
    "        optimizer (torch.optim): optimizer for training dqn\n",
    "        transition (list): transition information including \n",
    "                           state, action, reward, next_state, done\n",
    "        v_min (float): min value of support\n",
    "        v_max (float): max value of support\n",
    "        atom_size (int): the unit number of support\n",
    "        support (torch.Tensor): support for categorical dqn\n",
    "        use_n_step (bool): whether to use n_step memory\n",
    "        n_step (int): step number to calculate n-step td error\n",
    "        memory_n (ReplayBuffer): n-step replay buffer\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, \n",
    "        env: gym.Env,\n",
    "        memory_size: int,\n",
    "        batch_size: int,\n",
    "        target_update: int,\n",
    "        learning_rate: float = 3e-4,\n",
    "        gamma: float = 0.97,\n",
    "        # PER parameters\n",
    "        alpha: float = 0.2,\n",
    "        beta: float = 0.6,\n",
    "        prior_eps: float = 1e-6,\n",
    "        # Categorical DQN parameters\n",
    "        v_min: float = 0.0,\n",
    "        v_max: float = 200.0,\n",
    "        atom_size: int = 51,\n",
    "        # N-step Learning\n",
    "        n_step: int = 3,\n",
    "    ):\n",
    "        \"\"\"Initialization.\n",
    "        \n",
    "        Args:\n",
    "            env (gym.Env): openAI Gym environment\n",
    "            memory_size (int): length of memory\n",
    "            batch_size (int): batch size for sampling\n",
    "            target_update (int): period for target model's hard update\n",
    "            lr (float): learning rate\n",
    "            gamma (float): discount factor\n",
    "            alpha (float): determines how much prioritization is used\n",
    "            beta (float): determines how much importance sampling is used\n",
    "            prior_eps (float): guarantees every transition can be sampled\n",
    "            v_min (float): min value of support\n",
    "            v_max (float): max value of support\n",
    "            atom_size (int): the unit number of support\n",
    "            n_step (int): step number to calculate n-step td error\n",
    "        \"\"\"\n",
    "        obs_dim = env.observation_space.shape\n",
    "#         print(obs_dim)\n",
    "        action_dim = env.action_space.n\n",
    "        \n",
    "        self.env = env\n",
    "        self.batch_size = batch_size\n",
    "        self.target_update = target_update\n",
    "        self.gamma = gamma\n",
    "        # NoisyNet: All attributes related to epsilon are removed\n",
    "        \n",
    "        # device: cpu / gpu\n",
    "        self.device = torch.device(\n",
    "            \"cuda:4\" if torch.cuda.is_available() else \"cpu\"\n",
    "        )\n",
    "        print(self.device)\n",
    "        \n",
    "        # PER\n",
    "        # memory for 1-step Learning\n",
    "        self.beta = beta\n",
    "        self.prior_eps = prior_eps\n",
    "        self.replay_1 = ReplayBuffer(\n",
    "                obs_dim, memory_size, batch_size, n_step=1, gamma=gamma\n",
    "            )\n",
    "        self.memory = PrioritizedReplayBuffer(\n",
    "            obs_dim, memory_size, batch_size, alpha=alpha\n",
    "        )\n",
    "        \n",
    "        # memory for N-step Learning\n",
    "        self.use_n_step = True if n_step > 1 else False\n",
    "        if self.use_n_step:\n",
    "            self.n_step = n_step\n",
    "            self.memory_n = ReplayBuffer(\n",
    "                obs_dim, memory_size, batch_size, n_step=n_step, gamma=gamma\n",
    "            )\n",
    "            \n",
    "        # Categorical DQN parameters\n",
    "        self.v_min = v_min\n",
    "        self.v_max = v_max\n",
    "        self.atom_size = atom_size\n",
    "        self.support = torch.linspace(\n",
    "            self.v_min, self.v_max, self.atom_size\n",
    "        ).to(self.device)\n",
    "\n",
    "        # networks: dqn, dqn_target\n",
    "        self.dqn = RainbowNetwork(\n",
    "            obs_dim, action_dim, self.atom_size, self.support\n",
    "        ).to(self.device)\n",
    "        self.dqn_target = RainbowNetwork(\n",
    "            obs_dim, action_dim, self.atom_size, self.support\n",
    "        ).to(self.device)\n",
    "        self.dqn_target.load_state_dict(self.dqn.state_dict())\n",
    "        self.dqn_target.eval()\n",
    "        \n",
    "        # optimizer\n",
    "        self.optimizer = optim.Adam(self.dqn.parameters(), lr=learning_rate)\n",
    "\n",
    "        # transition to store in memory\n",
    "        self.transition = list()\n",
    "        \n",
    "        # mode: train / test\n",
    "        self.is_test = False\n",
    "\n",
    "    def select_action(self, state: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Select an action from the input state.\"\"\"\n",
    "        # NoisyNet: no epsilon greedy action selection\n",
    "        state = state.astype(int)\n",
    "        selected_action = self.dqn(\n",
    "            torch.FloatTensor(state).unsqueeze(0).to(self.device)\n",
    "        ).argmax()\n",
    "        selected_action = selected_action.detach().cpu().numpy()\n",
    "        \n",
    "        if not self.is_test:\n",
    "            self.transition = [state, selected_action]\n",
    "        \n",
    "        return selected_action\n",
    "\n",
    "    def step(self, action: np.ndarray):\n",
    "        \"\"\"Take an action and return the response of the env.\"\"\"\n",
    "        next_state, reward, done, _ = self.env.step(action)\n",
    "\n",
    "        if not self.is_test:\n",
    "            self.transition += [reward, next_state, done]\n",
    "            \n",
    "#             self.replay_1.store(*self.transition)\n",
    "            \n",
    "            # N-step transition\n",
    "            if self.use_n_step:\n",
    "                one_step_transition = self.memory_n.store(*self.transition)\n",
    "            # 1-step transition\n",
    "            else:\n",
    "                one_step_transition = self.transition\n",
    "\n",
    "            # add a single step transition\n",
    "            if one_step_transition:\n",
    "                self.memory.store(*one_step_transition)\n",
    "    \n",
    "        return next_state, reward, done\n",
    "\n",
    "    def update_model(self) -> torch.Tensor:\n",
    "        \"\"\"Update the model by gradient descent.\"\"\"\n",
    "        # PER needs beta to calculate weights\n",
    "        samples = self.memory.sample_batch(self.beta)\n",
    "#         samples = self.replay_1.sample_batch()\n",
    "    \n",
    "        weights = torch.FloatTensor(\n",
    "            samples[\"weights\"].reshape(-1, 1)\n",
    "        ).to(self.device)\n",
    "        indices = samples[\"indices\"]\n",
    "        \n",
    "        # 1-step Learning loss\n",
    "        elementwise_loss = self._compute_dqn_loss(samples, self.gamma)\n",
    "        \n",
    "        # PER: importance sampling before average\n",
    "        loss = torch.mean(elementwise_loss * weights)\n",
    "        \n",
    "        # N-step Learning loss\n",
    "        # we are gonna combine 1-step loss and n-step loss so as to\n",
    "        # prevent high-variance. The original rainbow employs n-step loss only.\n",
    "        \n",
    "        if self.use_n_step:\n",
    "            gamma = self.gamma ** self.n_step\n",
    "            samples = self.memory_n.sample_batch_from_idxs(indices)\n",
    "            elementwise_loss_n_loss = self._compute_dqn_loss(samples, gamma)\n",
    "            elementwise_loss += elementwise_loss_n_loss\n",
    "            \n",
    "            # PER: importance sampling before average\n",
    "            loss = torch.mean(elementwise_loss * weights)\n",
    "\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        clip_grad_norm_(self.dqn.parameters(), 10.0)\n",
    "        self.optimizer.step()\n",
    "        \n",
    "        # PER: update priorities\n",
    "        loss_for_prior = elementwise_loss.detach().cpu().numpy()\n",
    "        new_priorities = loss_for_prior + self.prior_eps\n",
    "        self.memory.update_priorities(indices, new_priorities)\n",
    "        \n",
    "        # NoisyNet: reset noise\n",
    "        self.dqn.reset_noise()\n",
    "        self.dqn_target.reset_noise()\n",
    "\n",
    "        return loss.item()\n",
    "        \n",
    "    def train(self, num_frames: int, plotting_interval: int = 2000, min_memory: int = 20000):\n",
    "        \"\"\"Train the agent.\"\"\"\n",
    "        self.is_test = False\n",
    "        \n",
    "        state = self.env.reset()\n",
    "        update_cnt = 0\n",
    "        losses = []\n",
    "        scores = []\n",
    "        score = 0\n",
    "\n",
    "        for frame_idx in range(1, num_frames + 1):\n",
    "            action = self.select_action(state)\n",
    "            next_state, reward, done = self.step(action)\n",
    "#             print(reward)\n",
    "\n",
    "            state = next_state\n",
    "            score += reward\n",
    "            \n",
    "            # NoisyNet: removed decrease of epsilon\n",
    "            \n",
    "            # PER: increase beta\n",
    "            fraction = min(frame_idx / num_frames, 1.0)\n",
    "            self.beta = self.beta + fraction * (1.0 - self.beta)\n",
    "\n",
    "            # if episode ends\n",
    "            if done:\n",
    "                state = env.reset()\n",
    "                scores.append(score)\n",
    "                score = 0\n",
    "\n",
    "            # if training is ready\n",
    "            if len(self.memory) >= min_memory: #self.batch_size:\n",
    "                loss = self.update_model()\n",
    "                losses.append(loss)\n",
    "                update_cnt += 1\n",
    "                \n",
    "                # if hard update is needed\n",
    "                if update_cnt % self.target_update == 0:\n",
    "                    self._target_hard_update()\n",
    "\n",
    "            # plotting\n",
    "            if frame_idx % plotting_interval == 0:\n",
    "                self._plot(frame_idx, scores, losses)\n",
    "                \n",
    "        self.env.close()\n",
    "                \n",
    "    def test(self) -> None:\n",
    "        \"\"\"Test the agent.\"\"\"\n",
    "        self.is_test = True\n",
    "        \n",
    "        state = self.env.reset()\n",
    "        done = False\n",
    "        score = 0\n",
    "        \n",
    "        while not done:\n",
    "            self.env.render()\n",
    "            action = self.select_action(state)\n",
    "            next_state, reward, done = self.step(action)\n",
    "\n",
    "            state = next_state\n",
    "            score += reward\n",
    "        \n",
    "        print(\"score: \", score)\n",
    "        self.env.close()\n",
    "\n",
    "    def _compute_dqn_loss(self, samples, gamma: float) -> torch.Tensor:\n",
    "        \"\"\"Return categorical dqn loss.\"\"\"\n",
    "        device = self.device  # for shortening the following lines\n",
    "        state = torch.FloatTensor(samples[\"obs\"]).to(device)\n",
    "        next_state = torch.FloatTensor(samples[\"next_obs\"]).to(device)\n",
    "        action = torch.LongTensor(samples[\"acts\"]).to(device)\n",
    "        reward = torch.FloatTensor(samples[\"rews\"].reshape(-1, 1)).to(device)\n",
    "        done = torch.FloatTensor(samples[\"done\"].reshape(-1, 1)).to(device)\n",
    "        \n",
    "        # Categorical DQN algorithm\n",
    "        delta_z = float(self.v_max - self.v_min) / (self.atom_size - 1)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # Double DQN\n",
    "            next_action = self.dqn(next_state).argmax(1)\n",
    "            next_dist = self.dqn_target.dist(next_state)\n",
    "            next_dist = next_dist[range(self.batch_size), next_action]\n",
    "\n",
    "            t_z = reward + (1 - done) * gamma * self.support\n",
    "            t_z = t_z.clamp(min=self.v_min, max=self.v_max)\n",
    "            b = (t_z - self.v_min) / delta_z\n",
    "            l = b.floor().long()\n",
    "            u = b.ceil().long()\n",
    "\n",
    "            offset = (\n",
    "                torch.linspace(\n",
    "                    0, (batch_size - 1) * self.atom_size, self.batch_size\n",
    "                ).long()\n",
    "                .unsqueeze(1)\n",
    "                .expand(self.batch_size, self.atom_size)\n",
    "                .to(self.device)\n",
    "            )\n",
    "\n",
    "            proj_dist = torch.zeros(next_dist.size(), device=self.device)\n",
    "            proj_dist.view(-1).index_add_(\n",
    "                0, (l + offset).view(-1), (next_dist * (u.float() - b)).view(-1)\n",
    "            )\n",
    "            proj_dist.view(-1).index_add_(\n",
    "                0, (u + offset).view(-1), (next_dist * (b - l.float())).view(-1)\n",
    "            )\n",
    "\n",
    "        dist = self.dqn.dist(state)\n",
    "        log_p = torch.log(dist[range(self.batch_size), action])\n",
    "        elementwise_loss = -(proj_dist * log_p).sum(1)\n",
    "\n",
    "        return elementwise_loss\n",
    "\n",
    "    def _target_hard_update(self):\n",
    "        \"\"\"Hard update: target <- local.\"\"\"\n",
    "        self.dqn_target.load_state_dict(self.dqn.state_dict())\n",
    "                \n",
    "    def _plot(\n",
    "        self, \n",
    "        frame_idx: int, \n",
    "        scores, \n",
    "        losses,\n",
    "    ):\n",
    "        \"\"\"Plot the training progresses.\"\"\"\n",
    "        clear_output(True)\n",
    "        plt.figure(figsize=(20, 5))\n",
    "        plt.subplot(131)\n",
    "        plt.title('frame %s. score: %s' % (frame_idx, np.mean(scores)))\n",
    "        plt.plot(scores)\n",
    "        plt.subplot(132)\n",
    "        plt.title('loss')\n",
    "        plt.plot(losses)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Env Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from safelife_factory import environment_factory\n",
    "import datetime\n",
    "from tensorboardX import SummaryWriter\n",
    "# from common.wrappers import make_atari, wrap_deepmind, wrap_pytorch\n",
    "\n",
    "# from env_factory import safelife_env_factory\n",
    "import datetime, os\n",
    "os.chdir('../')\n",
    "\n",
    "from training.env_factory import linear_schedule, safelife_env_factory\n",
    "from safelife.file_finder import SafeLifeLevelIterator\n",
    "\n",
    "t_penalty = [0.5e6, 1.5e6]\n",
    "t_performance = [0.5e6, 1.5e6]\n",
    "level_iterator = SafeLifeLevelIterator('random/prune-still-easy.yaml')\n",
    "test_levels = 'benchmarks/v1.0/prune-still.npz'\n",
    "\n",
    "subdir = './safelife-data/rainbow-2/'\n",
    "\n",
    "penalty = 0.0\n",
    "\n",
    "summary_writer = SummaryWriter(subdir)\n",
    "\n",
    "training_envs = safelife_env_factory(\n",
    "    logdir=subdir, summary_writer=summary_writer, num_envs=1,\n",
    "    impact_penalty=linear_schedule(t_penalty, [0, penalty]),\n",
    "    min_performance=linear_schedule(t_performance, [0.01, 0.5]),\n",
    "    level_iterator=level_iterator,\n",
    ")\n",
    "\n",
    "\n",
    "# env = environment_factory(safelife_levels =['random/prune-still'],\n",
    "#                           logdir='./safelife-data/prune-still-rainbow-1'+ datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<RecordingSafeLifeWrapper<MinPerformanceScheduler<SimpleSideEffectPenalty<ExtraExitBonus<MovementBonusWrapper<SafeLifeEnv instance>>>>>>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_envs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:4\n"
     ]
    }
   ],
   "source": [
    "seed = 777\n",
    "\n",
    "env = training_envs[0]\n",
    "\n",
    "# def seed_torch(seed):\n",
    "#     torch.manual_seed(seed)\n",
    "#     if torch.backends.cudnn.enabled:\n",
    "#         torch.backends.cudnn.benchmark = False\n",
    "#         torch.backends.cudnn.deterministic = True\n",
    "\n",
    "# np.random.seed(seed)\n",
    "# random.seed(seed)\n",
    "# seed_torch(seed)\n",
    "# env.seed(seed)\n",
    "\n",
    "\n",
    "# parameters\n",
    "num_frames = int(2e6)\n",
    "memory_size = int(1e5)\n",
    "batch_size = 128\n",
    "target_update = 1e4\n",
    "\n",
    "# train\n",
    "agent = DQNAgent(env, memory_size, batch_size, target_update)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "agent.train(num_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "safe_p3",
   "language": "python",
   "name": "safe_p3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
